{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da4db7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess as sp\n",
    "import yaml\n",
    "import shutil\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30106f3",
   "metadata": {},
   "source": [
    "# Convert notebooks to html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "934dc49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/ginoprasad/ginoprasad.github.io')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b1568a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = 'metadata.yaml'\n",
    "with open(metadata_path) as infile:\n",
    "    metadata = yaml.safe_load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5183729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for project_notebook_path in metadata['Projects'][:]:\n",
    "    if not os.path.exists(project_notebook_path):\n",
    "        print(f\"REMOVING {project_notebook_path}\")\n",
    "        metadata['Projects'].remove(project_notebook_path)\n",
    "        with open(metadata_path, 'w') as outfile:\n",
    "            yaml.dump(metadata, outfile, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "155f185e",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_path = f'{os.getcwd()}/projects/temp.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1b56a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_base_filename_length = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "321cf021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ginoprasad/ginoprasad.github.io/projects/temp.html'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05e1905d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ginoprasad/ai_stuff/edge_detector.ipynb'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_notebook_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0153e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████▋                  | 8/23 [00:00<00:00, 38.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ginoprasad/ai_stuff/earth_movers_distance.ipynb\n",
      "['{', ' \"cells\": [', '  {', '   \"cell_type\": \"markdown\",', '   \"id\": \"9f16d75b\",', '   \"metadata\": {},', '   \"source\": [', '    \"# Earth Mover\\'s Distance for NLP using Network Simplex\\\\n\",', '    \"<br>\\\\n\",', '    \"\\\\n\",', '    \"> #### Gino Prasad\\\\n\",', '    \"> #### 07/24/23\\\\n\"', '   ]', '  },', '  {', '   \"cell_type\": \"markdown\",', '   \"id\": \"3433b04d\",', '   \"metadata\": {},', '   \"source\": [', '    \"# Preview\"', '']\n",
      "/Users/ginoprasad/ai_stuff/chess_bot/mcst_alphazero.ipynb\n",
      "['{', ' \"cells\": [', '  {', '   \"cell_type\": \"markdown\",', '   \"id\": \"40e810ea\",', '   \"metadata\": {},', '   \"source\": [', '    \"# Deep Learning with Chess Monte Carlo Search Tree\"', '   ]', '  },', '  {', '   \"cell_type\": \"markdown\",', '   \"id\": \"999233ef\",', '   \"metadata\": {},', '   \"source\": [', '    \"## Defining Graph\"', '   ]', '  },', '  {', '   \"cell_type\": \"code\",', '']\n",
      "/Users/ginoprasad/ai_stuff/Translation/transformer_seq_to_seq.ipynb\n",
      "['{', ' \"cells\": [', '  {', '   \"cell_type\": \"markdown\",', '   \"metadata\": {},', '   \"source\": [', '    \"# English to French Translation using Transformers\\\\n\",', '    \"<br>\\\\n\",', '    \"\\\\n\",', '    \"> #### Gino Prasad\\\\n\",', '    \"> #### 07/02/23\\\\n\"', '   ]', '  },', '  {', '   \"cell_type\": \"markdown\",', '   \"metadata\": {},', '   \"source\": [', '    \"# Preview\"', '   ]', '  },', '']\n",
      "/Users/ginoprasad/ai_stuff/VAE_Face_Simulator/VAE_Face_Simulation.ipynb\n",
      "['{', ' \"cells\": [', '  {', '   \"cell_type\": \"markdown\",', '   \"metadata\": {},', '   \"source\": [', '    \"# Variational Auto Encoders for Simulating Human Faces\\\\n\",', '    \"<br>\\\\n\",', '    \"\\\\n\",', '    \"> #### Gino Prasad\\\\n\",', '    \"> #### 06/20/23\"', '   ]', '  },', '  {', '   \"cell_type\": \"markdown\",', '   \"metadata\": {},', '   \"source\": [', '    \"# Preview\"', '   ]', '  },', '']\n",
      "/Users/ginoprasad/ai_stuff/MusicTranscription/audio_transcription.ipynb\n",
      "['{', ' \"cells\": [', '  {', '   \"cell_type\": \"markdown\",', '   \"id\": \"e482bc79\",', '   \"metadata\": {},', '   \"source\": [', '    \"# MUS 15 Project 2: Audio Transcription\\\\n\",', '    \"<br>\\\\n\",', '    \"\\\\n\",', '    \"Gino Prasad, Saba Heydari Seradj, Ashish Dalvi\\\\n\",', '    \"\\\\n\",', '    \"For our MUS 15 project, our group created an audio transcriber from scratch. All of the code was made from scratch by us using python. \\\\n\",', '    \"\\\\n\",', '    \"We have uploaded this code to https://github.com/GinoP123/MusicTranscription\"', '   ]', '  },', '  {', '   \"cell_type\": \"code\",', '   \"execution_count\": 11,', '']\n",
      "/Users/ginoprasad/image_processing/cropping_image_logo.ipynb\n",
      "['{', ' \"cells\": [', '  {', '   \"cell_type\": \"markdown\",', '   \"id\": \"e1aca3e3\",', '   \"metadata\": {},', '   \"source\": [', '    \"# Cropping Image Logo for the Website\\\\n\",', '    \"<br>\\\\n\",', '    \"\\\\n\",', '    \"> #### Gino Prasad\\\\n\",', '    \"> #### 05/20/23\\\\n\"', '   ]', '  },', '  {', '   \"cell_type\": \"code\",', '   \"execution_count\": 46,', '   \"id\": \"1b1568a7\",', '   \"metadata\": {},', '   \"outputs\": [],', '']\n",
      "/Users/ginoprasad/ai_stuff/Stable_Diffusion_Pretrained.ipynb\n",
      "['{', ' \"cells\": [', '  {', '   \"cell_type\": \"markdown\",', '   \"metadata\": {', '    \"id\": \"neXCXJSF06eY\"', '   },', '   \"source\": [', '    \"# Using Pretrained Stable Diffusion for the Website Logo\\\\n\",', '    \"<br>\\\\n\",', '    \"\\\\n\",', '    \"> #### Gino Prasad\\\\n\",', '    \"> #### 05/18/23\\\\n\"', '   ]', '  },', '  {', '   \"cell_type\": \"markdown\",', '   \"metadata\": {', '    \"id\": \"Fedbwqa7l_Fj\"', '   },', '']\n",
      "/Users/ginoprasad/foobar/solution_11.ipynb\n",
      "['{', ' \"cells\": [', '  {', '   \"cell_type\": \"markdown\",', '   \"id\": \"04bad1a8\",', '   \"metadata\": {},', '   \"source\": [', '    \"# Google Foobar Expanding Nebula Problem\\\\n\",', '    \"<br>\\\\n\",', '    \"\\\\n\",', '    \"> #### Gino Prasad\\\\n\",', '    \"> #### 05/17/23\\\\n\",', '    \"\\\\n\",', '    \"This algorithm finds the Preimage Matrix for this cellular automata.\\\\n\",', '    \"Then, this uses dynamic programming to find the number of preimages\\\\n\",', '    \"for a given state.\\\\n\",', '    \"\\\\n\",', '    \"Here is my source for counting the number of preimage states:\\\\n\",', '    \"https://en.wikibooks.org/wiki/Cellular_Automata/Counting_Preimages\"', '   ]', '']\n",
      "/Users/ginoprasad/quantum_algorithms/complex_inner_product.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████▊        | 16/23 [00:00<00:00, 38.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['{', ' \"cells\": [', '  {', '   \"cell_type\": \"markdown\",', '   \"id\": \"81635586\",', '   \"metadata\": {},', '   \"source\": [', '    \"# Inner Product in Hilbert Space\\\\n\",', '    \"<br>\\\\n\",', '    \"\\\\n\",', '    \"> #### Gino Prasad\\\\n\",', '    \"> #### 05/08/23\\\\n\"', '   ]', '  },', '  {', '   \"cell_type\": \"markdown\",', '   \"id\": \"57efea84\",', '   \"metadata\": {},', '   \"source\": [', '    \"https://www.youtube.com/watch?v=3N2vN76E-QA&ab_channel=QuantumSense\"', '']\n",
      "/Users/ginoprasad/ai_stuff/autotune_phase_vocoder/Autotune_MUS_15.ipynb\n",
      "['{', ' \"cells\": [', '  {', '   \"cell_type\": \"markdown\",', '   \"id\": \"1865fd35\",', '   \"metadata\": {},', '   \"source\": [', '    \"# MUS 15 Project 1: Creating Autotune From Scratch Using Phase Vocoders\"', '   ]', '  },', '  {', '   \"cell_type\": \"markdown\",', '   \"id\": \"3c492546\",', '   \"metadata\": {},', '   \"source\": [', '    \"Gino Prasad, Saba Heydari Seradj, Ashish Dalvi\"', '   ]', '  },', '  {', '   \"cell_type\": \"markdown\",', '']\n",
      "/Users/ginoprasad/ai_stuff/autotune_phase_vocoder/Phase_Vocoder.ipynb\n",
      "['{', ' \"cells\": [', '  {', '   \"cell_type\": \"markdown\",', '   \"id\": \"3cf0d544\",', '   \"metadata\": {},', '   \"source\": [', '    \"# Phase Vocoder Implementation\"', '   ]', '  },', '  {', '   \"cell_type\": \"code\",', '   \"execution_count\": 5,', '   \"id\": \"23070df8\",', '   \"metadata\": {},', '   \"outputs\": [],', '   \"source\": [', '    \"import os\\\\n\",', '    \"import torch\\\\n\",', '    \"import torchaudio\\\\n\",', '']\n",
      "/Users/ginoprasad/ai_stuff/autotune_phase_vocoder/yin_pitch_prediction.ipynb\n",
      "['{', ' \"cells\": [', '  {', '   \"cell_type\": \"markdown\",', '   \"id\": \"2c689c0f\",', '   \"metadata\": {},', '   \"source\": [', '    \"# Yin Pitch Prediction Implementation\"', '   ]', '  },', '  {', '   \"cell_type\": \"code\",', '   \"execution_count\": 3,', '   \"id\": \"1bfa42cb\",', '   \"metadata\": {},', '   \"outputs\": [],', '   \"source\": [', '    \"import os\\\\n\",', '    \"import torch\\\\n\",', '    \"import torchaudio\\\\n\",', '']\n",
      "/Users/ginoprasad/ai_stuff/autotune_phase_vocoder/autotune_combined.ipynb\n",
      "['{', ' \"cells\": [', '  {', '   \"cell_type\": \"markdown\",', '   \"id\": \"bd04efe8\",', '   \"metadata\": {},', '   \"source\": [', '    \"# Autotune Implementation Using Phase Vocoder\"', '   ]', '  },', '  {', '   \"cell_type\": \"code\",', '   \"execution_count\": 1,', '   \"id\": \"151bbc75\",', '   \"metadata\": {},', '   \"outputs\": [],', '   \"source\": [', '    \"import os\\\\n\",', '    \"import torch\\\\n\",', '    \"import torchaudio\\\\n\",', '']\n",
      "/Users/ginoprasad/eng_math/fast_fourier_transform.ipynb\n",
      "['{', ' \"cells\": [', '  {', '   \"cell_type\": \"markdown\",', '   \"id\": \"56495805\",', '   \"metadata\": {},', '   \"source\": [', '    \"# Fast Fourier Transform Implementation\"', '   ]', '  },', '  {', '   \"cell_type\": \"markdown\",', '   \"id\": \"4ee643fd\",', '   \"metadata\": {},', '   \"source\": [', '    \"## Continuous Fourier Transform\"', '   ]', '  },', '  {', '   \"cell_type\": \"markdown\",', '']\n",
      "/Users/ginoprasad/ai_stuff/unet_implementation.ipynb\n",
      "['{', ' \"cells\": [', '  {', '   \"cell_type\": \"markdown\",', '   \"metadata\": {},', '   \"source\": [', '    \"# U-Net Convolutional Neural Network Implementation\"', '   ]', '  },', '  {', '   \"cell_type\": \"code\",', '   \"execution_count\": 11,', '   \"metadata\": {},', '   \"outputs\": [],', '   \"source\": [', '    \"import os\\\\n\",', '    \"import glob\"', '   ]', '  },', '  {', '']\n",
      "/Users/ginoprasad/ai_stuff/text_classifier/Multilayer Neural Network.ipynb\n",
      "['']\n",
      "/Users/ginoprasad/ai_stuff/text_classifier/Image Segmenter.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████| 23/23 [00:00<00:00, 38.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['']\n",
      "/Users/ginoprasad/ai_stuff/text_classifier/Handwriten Text Parser.ipynb\n",
      "['']\n",
      "/Users/ginoprasad/ai_stuff/Gaussian Blur Test.ipynb\n",
      "['']\n",
      "/Users/ginoprasad/ai_stuff/audio_transcriber/play_note.ipynb\n",
      "['{', ' \"cells\": [', '  {', '   \"cell_type\": \"markdown\",', '   \"id\": \"37bfc694\",', '   \"metadata\": {},', '   \"source\": [', '    \"# Pitch Reconstruction with Audio Processing\"', '   ]', '  },', '  {', '   \"cell_type\": \"code\",', '   \"execution_count\": 2,', '   \"id\": \"559c13b5\",', '   \"metadata\": {},', '   \"outputs\": [],', '   \"source\": [', '    \"from IPython.display import Audio\"', '   ]', '  },', '']\n",
      "/Users/ginoprasad/Wordle/wordle_bot.ipynb\n",
      "['{', ' \"cells\": [', '  {', '   \"cell_type\": \"markdown\",', '   \"id\": \"79ad2763\",', '   \"metadata\": {},', '   \"source\": [', '    \"# Wordle Bot\\\\n\",', '    \"<br>\\\\n\",', '    \"\\\\n\",', '    \"> #### Gino Prasad\\\\n\",', '    \"> #### 07/05/22\\\\n\"', '   ]', '  },', '  {', '   \"cell_type\": \"markdown\",', '   \"id\": \"39844eac\",', '   \"metadata\": {},', '   \"source\": [', '    \"# Preview\"', '']\n",
      "/Users/ginoprasad/eng_math/interpolation.ipynb\n",
      "['{', ' \"cells\": [', '  {', '   \"cell_type\": \"markdown\",', '   \"id\": \"f94008f2\",', '   \"metadata\": {},', '   \"source\": [', '    \"# Lagrange Interpolation and Gregory-Newton Interpolation\"', '   ]', '  },', '  {', '   \"cell_type\": \"code\",', '   \"execution_count\": 2,', '   \"id\": \"caa34b76\",', '   \"metadata\": {},', '   \"outputs\": [],', '   \"source\": [', '    \"def delta(k, delta_cache):\\\\n\",', '    \"    if len(delta_cache) <= k:\\\\n\",', '    \"        for _ in range(k - len(delta_cache) + 1):\\\\n\",', '']\n",
      "/Users/ginoprasad/ai_stuff/edge_detector.ipynb\n",
      "['{', ' \"cells\": [', '  {', '   \"cell_type\": \"markdown\",', '   \"id\": \"d3d35e4f\",', '   \"metadata\": {},', '   \"source\": [', '    \"# Image Edge Detector\"', '   ]', '  },', '  {', '   \"cell_type\": \"code\",', '   \"execution_count\": 18,', '   \"id\": \"cb3f8525\",', '   \"metadata\": {},', '   \"outputs\": [],', '   \"source\": [', '    \"import tensorflow as tf\\\\n\",', '    \"import numpy as np\"', '   ]', '']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "project_names, project_paths = [], []\n",
    "for project_notebook_path in tqdm(metadata['Projects']):\n",
    "\n",
    "    print(project_notebook_path)\n",
    "    title_line = sp.run(f\"head -n 20 {project_notebook_path}\", shell=True, capture_output=True).stdout.decode().split('\\n')\n",
    "    print(title_line)\n",
    "    title_line = ipynb_yaml[\"cells\"][0][\"source\"][0]\n",
    "    project_name = title_line.strip().lstrip('# ')\n",
    "    \n",
    "    project_base_path = os.path.basename(project_notebook_path)[:-len('.ipynb')]\n",
    "    while len(project_base_path) > max_base_filename_length:\n",
    "        project_base_path = ' '.join(project_base_path.split(' ')[:-1])\n",
    "    if not project_base_path:\n",
    "        print(f\"\\n\\n\\n\\n\\tWarning: Project '{project_name}' Name exceeds recommended length\\n\\n\\n\\n\")\n",
    "        project_base_path = project_name\n",
    "    project_path = f'{os.getcwd()}/projects/{project_base_path}.html'\n",
    "    \n",
    "    if os.path.getmtime(project_path) > os.path.getmtime(project_notebook_path):\n",
    "        continue\n",
    "    \n",
    "    print(project_base_path)\n",
    "    print(f\"Converting {project_notebook_path}\")\n",
    "    sp.run(f\"jupyter nbconvert --to html '{project_notebook_path}' --output '{temp_path}'\", shell=True)\n",
    "    print(f'Project Name: {project_name}')\n",
    "\n",
    "    with open(temp_path) as infile:\n",
    "        lines = infile.readlines()\n",
    "\n",
    "\n",
    "    title = ' '.join(map(lambda x: x[0].upper() + x[1:] if x else x, project_base_path.split('_')))\n",
    "    lines[5] = lines[5][:len('<title>')] + title + lines[5][lines[5].index('</title>'):]\n",
    " \n",
    "    with open(temp_path, 'w') as outfile:\n",
    "        lines.insert(5, '<link rel=\"icon\" href=\"../docs/assets/logo.png\"><iframe src=\"../header.html\" style=\"height: 12rem; width: 100%\" frameborder=\"0\" scrolling=\"no\"></iframe>\\n')\n",
    "        outfile.write(''.join(lines))\n",
    "    \n",
    "    assert project_path not in project_paths\n",
    "    os.rename(temp_path, project_path)\n",
    "    \n",
    "    project_names.append(project_name)\n",
    "    project_paths.append(project_path)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "945828dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Earth Mover's Distance for NLP using Network Simplex\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2eaadff",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_html_path = 'index.html'\n",
    "index_html_lines = open(index_html_path).readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "949099ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "publications_list_index_start = [\"Publications\" in x for x in index_html_lines].index(True) + 2\n",
    "publications_list_index_end = index_html_lines[publications_list_index_start:].index('\\t\\t</ul>\\n') + publications_list_index_start\n",
    "\n",
    "publications_list = []\n",
    "for publication in metadata['Publications']:\n",
    "    name = publication['name']\n",
    "    publications_list.append(f'\\t\\t\\t<li>\\n\\t\\t\\t\\t<p>{name}<p>\\n\\t\\t\\t\\t<h3>&emsp;&emsp;{publication[\"journal\"]}</h3>\\n\\t\\t\\t\\t&emsp;&emsp;&emsp;&emsp;<a href=\"{publication[\"doi\"]}\">{publication[\"doi\"]}</a>\\n\\t\\t\\t</li>\\n')\n",
    "index_html_lines = index_html_lines[:publications_list_index_start] + publications_list + index_html_lines[publications_list_index_end:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52ad2069",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_list_index_start = [\"Cool Projects\" in x for x in index_html_lines].index(True) + 2\n",
    "project_list_index_end = index_html_lines[project_list_index_start:].index('\\t\\t</ul>\\n') + project_list_index_start\n",
    "\n",
    "new_project_list =  [f'\\t\\t\\t<li><a href=\"projects/{os.path.basename(html_path)}\">{name}</a></li>\\n' for name, html_path in zip(project_names, project_paths)]\n",
    "index_html_lines = index_html_lines[:project_list_index_start] + new_project_list + index_html_lines[project_list_index_end:]\n",
    "index_html_lines[project_list_index_start-2] = f\"\\t\\t<h2> Cool Projects ({len(metadata['Projects'])}) </h2>\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7745fbd",
   "metadata": {},
   "source": [
    "# Copying CV and Updating Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e3b72ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert shutil.copy(metadata['CV'], f\"projects/{os.path.basename(metadata['CV'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5967d7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_dict = {tag: metadata[tag] for tag in ['CV', 'LinkedIn', 'GitHub']}\n",
    "tag_dict['CV'] = f\"projects/{os.path.basename(tag_dict['CV'])}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a7d174f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, line in enumerate(index_html_lines):\n",
    "    for tag in tag_dict:\n",
    "        prefix = f\"<a id='{tag}' href='\"\n",
    "        if line.startswith(prefix):\n",
    "            print(line.strip())\n",
    "            new_line = prefix + tag_dict[tag] + line[len(prefix) + line[len(prefix):].index(\"'\"):]\n",
    "            print(new_line)\n",
    "            index_html_lines[i] = new_line\n",
    "    \n",
    "    if line.startswith(prefix):\n",
    "        del tag_dict[tag]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549403c3",
   "metadata": {},
   "source": [
    "# Writing Updated Index File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d55453c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(index_html_path, 'w') as outfile:\n",
    "    outfile.write(''.join(index_html_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b451d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main ddf8b06] Automated Website Update\n",
      " 2 files changed, 28 insertions(+), 429 deletions(-)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "remote: This repository moved. Please use the new location:        \n",
      "remote:   https://github.com/GinoP123/ginoprasad.github.io.git        \n",
      "To https://github.com/ginoprasad/ginoprasad.github.io\n",
      "   cb205d6..ddf8b06  main -> main\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=\"cd '/Users/ginoprasad/ginoprasad.github.io'; git add .; git commit -m 'Automated Website Update'; git push origin main\", returncode=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.run(f\"cd '{os.getcwd()}'; git add .; git commit -m 'Automated Website Update'; git push origin main\", shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea967e3c",
   "metadata": {},
   "source": [
    "# Updating Python Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9589d4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook update_website.ipynb to script\n",
      "[NbConvertApp] Writing 5177 bytes to update_website.py\n"
     ]
    }
   ],
   "source": [
    "if hasattr(__builtins__,'__IPYTHON__'):\n",
    "    sp.run(f\"jupyter nbconvert --to script 'update_website.ipynb' --output 'update_website'\", shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed11ef25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
